use std::{
    collections::HashMap,
    sync::{Arc, Mutex},
};

use async_trait::async_trait;
use empath_common::context::Context;
use tokio::sync::Notify;

/// Identifier for a spooled message
///
/// This is a globally unique identifier (ULID) that serves as both the tracking ID
/// and the filename for spooled messages. ULIDs are lexicographically sortable by
/// creation time and collision-resistant.
#[derive(Debug, Clone, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct SpooledMessageId {
    id: ulid::Ulid,
}

impl SpooledMessageId {
    /// Parse a message ID from a filename like `01ARYZ6S41.bin` or `01ARYZ6S41.eml`
    ///
    /// Validates that the filename is a valid ULID to prevent path traversal attacks.
    ///
    /// # Security
    /// This function explicitly rejects:
    /// - Path separators (/ and \)
    /// - Directory traversal patterns (..)
    /// - Invalid ULID format
    pub fn from_filename(filename: &str) -> Option<Self> {
        // Reject filenames with path separators
        if filename.contains('/') || filename.contains('\\') {
            return None;
        }

        // Reject filenames with directory traversal patterns
        if filename.contains("..") {
            return None;
        }

        // Strip file extension
        let stem = filename
            .strip_suffix(".bin")
            .or_else(|| filename.strip_suffix(".eml"))?;

        // Parse as ULID
        let id = ulid::Ulid::from_string(stem).ok()?;

        Some(Self { id })
    }

    /// Create a new message ID from a ULID
    #[must_use]
    pub const fn new(id: ulid::Ulid) -> Self {
        Self { id }
    }

    /// Generate a new unique message ID
    #[must_use]
    pub fn generate() -> Self {
        Self {
            id: ulid::Ulid::new(),
        }
    }

    /// Get the underlying ULID
    #[must_use]
    pub const fn ulid(&self) -> ulid::Ulid {
        self.id
    }

    /// Get the timestamp (milliseconds since Unix epoch) encoded in this ULID
    ///
    /// This can be useful for observability, logging, and metrics.
    #[must_use]
    pub const fn timestamp_ms(&self) -> u64 {
        self.id.timestamp_ms()
    }
}

impl std::fmt::Display for SpooledMessageId {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.id)
    }
}

impl serde::Serialize for SpooledMessageId {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        serializer.serialize_str(&self.id.to_string())
    }
}

impl<'de> serde::Deserialize<'de> for SpooledMessageId {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let s = String::deserialize(deserializer)?;
        let id = ulid::Ulid::from_string(&s).map_err(serde::de::Error::custom)?;
        Ok(Self { id })
    }
}

/// Trait for the underlying storage mechanism
///
/// This trait defines the core operations for message storage backends.
/// Implementations can store messages in memory, on disk, in databases, etc.
///
/// # Trait Object Safety
/// This trait uses `async_trait` to remain dyn-safe, allowing for
/// `Arc<dyn BackingStore>` trait objects. While this adds a small Box
/// allocation per async call (~10-20ns), this overhead is negligible
/// compared to I/O operations (microseconds to milliseconds).
///
/// # Security
/// Implementations must:
/// - Validate all inputs (especially IDs to prevent path traversal)
/// - Handle concurrent access safely
/// - Prevent data corruption during writes
#[async_trait]
pub trait BackingStore: Send + Sync + std::fmt::Debug {
    /// Write a context to the backing store and return its tracking ID
    ///
    /// The tracking ID is generated by the backing store and is guaranteed to be unique.
    /// The tracking ID will be set in the context's `tracking_id` field.
    ///
    /// # Errors
    /// Returns an error if the context cannot be written
    async fn write(&self, context: Context) -> crate::Result<SpooledMessageId>;

    /// List all message identifiers
    ///
    /// Messages should be returned in sorted order (by creation time, lexicographically)
    ///
    /// # Errors
    /// Returns an error if the backing store cannot be read
    async fn list(&self) -> crate::Result<Vec<SpooledMessageId>>;

    /// Read a specific message and return its full context
    ///
    /// # Errors
    /// Returns an error if the message cannot be found or read
    async fn read(&self, id: &SpooledMessageId) -> crate::Result<Context>;

    /// Delete a message
    ///
    /// # Errors
    /// Returns an error if the message cannot be deleted
    async fn delete(&self, id: &SpooledMessageId) -> crate::Result<()>;
}

/// Main Spool struct - generic over backing store
///
/// This provides a unified interface for message spooling, regardless of
/// the underlying storage mechanism. The generic parameter `T` allows for
/// zero-cost abstraction when using concrete types, while still supporting
/// trait objects (`Arc<dyn BackingStore>`) for dynamic dispatch.
///
/// # Type Parameters
/// * `T` - The backing store implementation
///
/// # Examples
/// ```ignore
/// // Memory-backed spool for testing
/// let spool = Spool::new(MemoryBackingStore::new());
///
/// // File-backed spool for production
/// let store = FileBackingStore::builder()
///     .path(PathBuf::from("/var/spool/empath"))
///     .build()?;
/// let spool = Spool::new(store);
///
/// // Trait object for polymorphism
/// let store: Arc<dyn BackingStore> = Arc::new(MemoryBackingStore::new());
/// ```
#[derive(Debug, serde::Deserialize)]
#[serde(transparent)]
pub struct Spool<T: BackingStore> {
    #[serde(bound(deserialize = "T: serde::Deserialize<'de>"))]
    store: T,
}

impl<T: BackingStore + Default> Default for Spool<T> {
    fn default() -> Self {
        Self {
            store: T::default(),
        }
    }
}

impl<T: BackingStore> Spool<T> {
    /// Create a new spool with the given backing store
    #[must_use]
    pub const fn new(store: T) -> Self {
        Self { store }
    }

    /// Spool a context to the backing store and return its tracking ID
    ///
    /// The tracking ID is generated by the backing store and is guaranteed to be unique.
    ///
    /// # Errors
    /// Returns an error if the context cannot be written to the backing store
    pub async fn spool_message(&self, context: Context) -> crate::Result<SpooledMessageId> {
        self.store.write(context).await
    }

    /// List all spooled message identifiers
    ///
    /// # Errors
    /// Returns an error if the backing store cannot be read
    pub async fn list_messages(&self) -> crate::Result<Vec<SpooledMessageId>> {
        self.store.list().await
    }

    /// Read a specific message from the spool and return its full context
    ///
    /// # Errors
    /// Returns an error if the message cannot be found or read
    pub async fn read_message(&self, id: &SpooledMessageId) -> crate::Result<Context> {
        self.store.read(id).await
    }

    /// Delete a message from the spool
    ///
    /// # Errors
    /// Returns an error if the message cannot be deleted
    pub async fn delete_message(&self, id: &SpooledMessageId) -> crate::Result<()> {
        self.store.delete(id).await
    }

    /// Access the underlying backing store
    ///
    /// This is useful for store-specific operations not exposed through
    /// the standard Spool interface.
    #[must_use]
    pub const fn store(&self) -> &T {
        &self.store
    }

    /// Mutably access the underlying backing store
    #[must_use]
    pub const fn store_mut(&mut self) -> &mut T {
        &mut self.store
    }
}

/// Clone implementation - only available when T is Clone
///
/// This allows cheap cloning for backing stores that use Arc internally,
/// while preventing cloning for stores where it doesn't make sense.
impl<T: BackingStore + Clone> Clone for Spool<T> {
    fn clone(&self) -> Self {
        Self {
            store: self.store.clone(),
        }
    }
}

/// In-memory backing store implementation
///
/// This implementation stores messages in a `HashMap` protected by a Mutex.
/// It's primarily intended for testing, but can also be used for transient
/// message handling.
///
/// # Capacity Management
/// The store can be configured with a maximum capacity to prevent unbounded
/// memory growth. When capacity is reached, write operations will fail with
/// an error. This is useful for:
/// - Testing capacity-related error handling
/// - Preventing memory exhaustion if accidentally used in production
/// - Simulating resource constraints
///
/// # Performance
/// - Write: O(1) -`HashMap` insert + Arc clone (plus capacity check)
/// - List: O(n log n) - Must clone all keys and sort
/// - Read: O(1) - `HashMap` lookup + Context clone
/// - Delete: O(1) - `HashMap` remove
///
/// # Concurrency
/// Uses a Mutex for interior mutability. While this serializes all operations,
/// it's acceptable for testing scenarios. Production workloads should use
/// file-backed or database-backed stores with better concurrency primitives.
#[derive(Debug, Clone)]
pub struct MemoryBackingStore {
    messages: Arc<Mutex<HashMap<SpooledMessageId, Context>>>,
    /// Maximum number of messages to store (None = unlimited)
    capacity: Option<usize>,
}

impl MemoryBackingStore {
    /// Create a new empty memory-backed store with unlimited capacity
    #[must_use]
    pub fn new() -> Self {
        Self {
            messages: Arc::new(Mutex::new(HashMap::new())),
            capacity: None,
        }
    }

    /// Create a new memory-backed store with a capacity limit
    ///
    /// # Examples
    /// ```ignore
    /// // Limit to 1000 messages
    /// let store = MemoryBackingStore::with_capacity(1000);
    /// ```
    #[must_use]
    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            messages: Arc::new(Mutex::new(HashMap::new())),
            capacity: Some(capacity),
        }
    }

    /// Get the current number of messages in the store
    ///
    /// Recovers gracefully if the mutex is poisoned by accessing the underlying data.
    #[must_use]
    pub fn len(&self) -> usize {
        self.messages
            .lock()
            .unwrap_or_else(std::sync::PoisonError::into_inner)
            .len()
    }

    /// Check if the store is empty
    #[must_use]
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Get the configured capacity (None = unlimited)
    #[must_use]
    pub const fn capacity(&self) -> Option<usize> {
        self.capacity
    }
}

impl Default for MemoryBackingStore {
    fn default() -> Self {
        Self::new()
    }
}

#[async_trait]
impl BackingStore for MemoryBackingStore {
    async fn write(&self, mut context: Context) -> crate::Result<SpooledMessageId> {
        use crate::error::SpoolError;

        // Generate unique ULID
        let id = SpooledMessageId::generate();

        // Set the tracking ID in the context
        context.tracking_id = Some(id.to_string());

        let mut messages = self.messages.lock()?;

        // Check capacity before inserting (don't count if overwriting existing)
        if let Some(cap) = self.capacity
            && !messages.contains_key(&id)
            && messages.len() >= cap
        {
            return Err(SpoolError::Internal(format!(
                "Memory spool capacity exceeded: {}/{} messages",
                messages.len(),
                cap
            )));
        }

        messages.insert(id.clone(), context);
        // Clippy suggests that: temporary with significant `Drop` can be early dropped
        drop(messages);

        Ok(id)
    }

    async fn list(&self) -> crate::Result<Vec<SpooledMessageId>> {
        let mut ids: Vec<_> = self.messages.lock()?.keys().cloned().collect();

        // ULIDs are lexicographically sortable by creation time
        ids.sort();

        Ok(ids)
    }

    async fn read(&self, id: &SpooledMessageId) -> crate::Result<Context> {
        use crate::error::SpoolError;

        self.messages
            .lock()?
            .get(id)
            .cloned()
            .ok_or_else(|| SpoolError::NotFound(id.clone()))
    }

    async fn delete(&self, id: &SpooledMessageId) -> crate::Result<()> {
        use crate::error::SpoolError;

        self.messages
            .lock()?
            .remove(id)
            .ok_or_else(|| SpoolError::NotFound(id.clone()))?;
        Ok(())
    }
}

/// Type alias for memory-backed spool
pub type MemorySpool = Spool<MemoryBackingStore>;

/// Testing utilities for memory-backed spool
///
/// This wrapper adds test-specific functionality like waiting for operations
/// to complete and clearing the store.
#[derive(Debug, Clone)]
pub struct TestBackingStore {
    inner: MemoryBackingStore,
    notify: Arc<Notify>,
}

impl Default for TestBackingStore {
    fn default() -> Self {
        Self {
            inner: MemoryBackingStore::new(),
            notify: Arc::new(Notify::new()),
        }
    }
}

impl TestBackingStore {
    /// Create a new test backing store
    pub fn new() -> Self {
        Self::default()
    }

    /// Wait for the next message to be spooled
    ///
    /// This is useful in tests to ensure spool operations complete before assertions
    pub async fn wait_for_spool(&self) {
        self.notify.notified().await;
    }

    /// Wait for a specific number of messages to be spooled, with timeout
    ///
    /// # Errors
    /// Returns an error if the timeout is reached before the expected count
    pub async fn wait_for_count(
        &self,
        expected: usize,
        timeout: std::time::Duration,
    ) -> crate::Result<()> {
        use crate::error::SpoolError;

        tokio::time::timeout(timeout, async {
            loop {
                let count = self.inner.list().await.unwrap_or_default().len();
                if count >= expected {
                    return;
                }
                self.notify.notified().await;
            }
        })
        .await
        .map_err(|e| SpoolError::Internal(format!("Timeout waiting for messages: {e}")))?;
        Ok(())
    }

    /// Clear all messages from the store
    ///
    /// # Errors
    /// If there was an isue getting the lock for the message store, e.g. the lock has been poisoned
    #[allow(clippy::unused_async)]
    pub async fn clear(&self) -> crate::Result<()> {
        self.inner.messages.lock()?.clear();
        Ok(())
    }

    /// Get the number of spooled messages
    ///
    /// Recovers gracefully if the mutex is poisoned.
    #[allow(clippy::unused_async)]
    pub async fn message_count(&self) -> usize {
        self.inner
            .messages
            .lock()
            .unwrap_or_else(std::sync::PoisonError::into_inner)
            .len()
    }

    /// Get all messages (for test assertions)
    ///
    /// # Errors
    /// If there is an issue with listing the messages inside this store
    pub async fn messages(&self) -> crate::Result<Vec<Context>> {
        let ids = self.inner.list().await?;
        let mut messages = Vec::new();
        for id in ids {
            messages.push(self.inner.read(&id).await?);
        }
        Ok(messages)
    }
}

#[async_trait]
impl BackingStore for TestBackingStore {
    async fn write(&self, context: Context) -> crate::Result<SpooledMessageId> {
        let id = self.inner.write(context).await?;
        self.notify.notify_waiters();
        Ok(id)
    }

    async fn list(&self) -> crate::Result<Vec<SpooledMessageId>> {
        self.inner.list().await
    }

    async fn read(&self, id: &SpooledMessageId) -> crate::Result<Context> {
        self.inner.read(id).await
    }

    async fn delete(&self, id: &SpooledMessageId) -> crate::Result<()> {
        self.inner.delete(id).await
    }
}

/// Type alias for test spool
pub type TestSpool = Spool<TestBackingStore>;

#[cfg(test)]
mod tests {
    use std::sync::Arc;

    use ahash::AHashMap;

    use super::*;

    fn create_test_context(data: &str) -> Context {
        use empath_common::envelope::Envelope;

        Context {
            envelope: Envelope::default(),
            data: Some(Arc::from(data.as_bytes())),
            id: "test.example.com".to_string(),
            extended: false,
            metadata: AHashMap::new(),
            ..Default::default()
        }
    }

    #[tokio::test]
    async fn test_memory_store_basic_operations() {
        let store = MemoryBackingStore::new();
        let context = create_test_context("test message");
        let expected_data = context.data.clone();

        // Write context and get tracking ID
        let id = store.write(context).await.expect("Failed to write");

        // List messages
        let ids = store.list().await.expect("Failed to list");
        assert_eq!(ids.len(), 1);
        assert_eq!(ids[0], id);

        // Read context
        let read_ctx = store.read(&id).await.expect("Failed to read");
        assert_eq!(read_ctx.data.as_deref(), expected_data.as_deref());
        assert_eq!(read_ctx.tracking_id, Some(id.to_string()));

        // Delete message
        store.delete(&id).await.expect("Failed to delete");
        let ids_after = store.list().await.expect("Failed to list");
        assert_eq!(ids_after.len(), 0);
    }

    #[tokio::test]
    async fn test_memory_store_capacity_limit() {
        let store = MemoryBackingStore::with_capacity(2);

        // Write up to capacity
        let ctx1 = create_test_context("message 1");
        let ctx2 = create_test_context("message 2");
        store.write(ctx1).await.expect("First write should succeed");
        store
            .write(ctx2)
            .await
            .expect("Second write should succeed");

        // Third write should fail
        let ctx3 = create_test_context("message 3");
        let result = store.write(ctx3.clone()).await;
        assert!(result.is_err());
        assert!(
            result
                .unwrap_err()
                .to_string()
                .contains("capacity exceeded")
        );

        // After deleting one, we should be able to write again
        let ids = store.list().await.expect("Failed to list");
        store.delete(&ids[0]).await.expect("Failed to delete");

        let result = store.write(ctx3).await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_unique_id_generation() {
        let store = MemoryBackingStore::new();

        // Write multiple messages concurrently
        let mut handles = vec![];
        for i in 0..100 {
            let store_clone = store.clone();
            let handle = tokio::spawn(async move {
                let msg = create_test_context(&format!("message {i}"));
                store_clone.write(msg).await
            });
            handles.push(handle);
        }

        // Wait for all writes
        for handle in handles {
            handle.await.expect("Task panicked").expect("Write failed");
        }

        // All IDs should be unique
        let ids = store.list().await.expect("Failed to list");
        assert_eq!(ids.len(), 100);

        // Check for uniqueness
        let mut id_set = std::collections::HashSet::new();
        for id in &ids {
            assert!(id_set.insert(id.clone()), "Found duplicate ID: {id}");
        }
    }

    #[tokio::test]
    async fn test_spool_wrapper() {
        let store = MemoryBackingStore::new();
        let spool = Spool::new(store);

        let message = create_test_context("test message");
        let expected_data = message.data.clone();

        // Test through Spool interface and get tracking ID
        let id = spool.spool_message(message).await.expect("Failed to spool");

        let ids = spool.list_messages().await.expect("Failed to list");
        assert_eq!(ids.len(), 1);
        assert_eq!(ids[0], id);

        let read_msg = spool.read_message(&id).await.expect("Failed to read");
        assert_eq!(read_msg.data.as_ref(), expected_data.as_ref());

        spool.delete_message(&id).await.expect("Failed to delete");

        let ids_after = spool.list_messages().await.expect("Failed to list");
        assert_eq!(ids_after.len(), 0);
    }

    #[tokio::test]
    async fn test_polymorphic_backing_store() {
        // Test that we can use trait objects
        let store: Arc<dyn BackingStore> = Arc::new(MemoryBackingStore::new());
        let message = create_test_context("polymorphic test");
        let expected_data = message.data.clone();

        let id = store.write(message).await.expect("Failed to write");
        let ids = store.list().await.expect("Failed to list");
        assert_eq!(ids.len(), 1);
        assert_eq!(ids[0], id);

        let read_msg = store.read(&id).await.expect("Failed to read");
        assert_eq!(read_msg.data.as_ref(), expected_data.as_ref());
    }

    #[tokio::test]
    async fn test_message_ordering() {
        let store = MemoryBackingStore::new();

        // Write messages and collect IDs in generation order
        let mut generated_ids = Vec::new();
        for i in 0..10 {
            let msg = create_test_context(&format!("message {i}"));
            let id = store.write(msg).await.expect("Failed to write");
            generated_ids.push(id);
        }

        // List should return sorted lexicographically
        let listed_ids = store.list().await.expect("Failed to list");
        assert_eq!(listed_ids.len(), 10);

        // Sort the generated IDs and verify they match the listed order
        // This tests that list() properly sorts ULIDs without relying on timing
        generated_ids.sort();
        assert_eq!(
            generated_ids, listed_ids,
            "Listed IDs should match sorted generation order"
        );

        // Verify all IDs are unique (additional sanity check)
        let unique_count = generated_ids
            .iter()
            .collect::<std::collections::HashSet<_>>()
            .len();
        assert_eq!(unique_count, 10, "All ULIDs should be unique");
    }

    #[tokio::test]
    async fn test_mutex_poisoning_recovery() {
        let store = MemoryBackingStore::new();

        // len() should recover from poisoned mutex
        let len = store.len();
        assert_eq!(len, 0);

        // Write and verify recovery
        let msg = create_test_context("test");
        store.write(msg).await.expect("Failed to write");
        assert_eq!(store.len(), 1);
        assert!(!store.is_empty());
    }

    #[test]
    fn test_spooled_message_id_validation() {
        // Valid ULIDs (26 characters)
        assert!(SpooledMessageId::from_filename("01ARZ3NDEKTSV4RRFFQ69G5FAV.bin").is_some());
        assert!(SpooledMessageId::from_filename("01ARZ3NDEKTSV4RRFFQ69G5FAV.eml").is_some());

        // Invalid IDs (security)
        assert!(SpooledMessageId::from_filename("../etc/passwd.bin").is_none());
        assert!(SpooledMessageId::from_filename("foo/bar.bin").is_none());
        assert!(SpooledMessageId::from_filename("..\\windows\\system32.bin").is_none());

        // Invalid IDs (format)
        assert!(SpooledMessageId::from_filename("not_a_valid_ulid.bin").is_none());
        assert!(SpooledMessageId::from_filename("1234567890.bin").is_none());
        assert!(SpooledMessageId::from_filename("1234567890_42.bin").is_none()); // Old format

        // Invalid extension (no longer supported)
        assert!(SpooledMessageId::from_filename("01ARZ3NDEKTSV4RRFFQ69G5FAV.json").is_none());
    }

    #[test]
    fn test_capacity_methods() {
        let unlimited = MemoryBackingStore::new();
        assert_eq!(unlimited.capacity(), None);

        let limited = MemoryBackingStore::with_capacity(100);
        assert_eq!(limited.capacity(), Some(100));
    }
}
